{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fi_VO8r3R1TT"
   },
   "source": [
    "# Analyzing A Movie Review Dataset[100 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gd1nFWBCP7GC"
   },
   "source": [
    "## 0. Text Preprocessing [10 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaeN3k-w_ygu"
   },
   "source": [
    "Read through this tutorial on kaggle [here](\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words) , to\n",
    "familiarize yourself with its python tools and workflow. You'll have to download \"labeledTrainData.tsv\" and \"testData.tsv\" from [here](https://www.kaggle.com/c/word2vec-nlp-tutorial/data). Please remember to add your GT_UserName in the author function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IZAcFI1WbCc4",
    "outputId": "33b0e186-0bcb-4210-e15a-d6f90a59b4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This assignment is submitted by tpasumarthi3.\n"
     ]
    }
   ],
   "source": [
    "def author(gt_username = 'tpasumarthi3'):\n",
    "    print(\"This assignment is submitted by {0}.\".format(gt_username))\n",
    "\n",
    "#Add your GT_UserName below and uncomment the line.\n",
    "author()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIpeJ8VmR1TX"
   },
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIvs0LVJR1Te"
   },
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", delimiter=\"\\t\")\n",
    "test = pd.read_csv(\"testData.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ano1yq7oR1Th"
   },
   "outputs": [],
   "source": [
    "def preprocess_review(review):\n",
    "    \"\"\"Helper function to clean the reviews.\n",
    "\n",
    "     Arg: review: review text.\n",
    "     Returns: clean_review : Cleaned reviews\n",
    "\n",
    "     You should carry out the following steps.\n",
    "     1. Remove HTML Tags.\n",
    "     2. Remove non-letter characters.\n",
    "     3. Convert to lower case.\n",
    "     4. Remove stopwords.\n",
    "    \"\"\"\n",
    "\n",
    "    #Write your code below\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    #nltk.download('stopwords')\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))\n",
    "    \n",
    "    return clean_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJERbiU0R1Tj"
   },
   "outputs": [],
   "source": [
    "#Clean the reviews and add them to the list below\n",
    "cleaned_reviews = []\n",
    "\n",
    "#Write your code below.\n",
    "num_reviews = train[\"review\"].size \n",
    "for i in range(num_reviews):\n",
    "    cleaned_reviews.append(preprocess_review( train[\"review\"][i] ))\n",
    "\n",
    "    \n",
    "#Clean the test reviews and add them to the list below\n",
    "cleaned_test_reviews = []\n",
    "\n",
    "#Write your code below.\n",
    "num_test_reviews = test[\"review\"].size \n",
    "for i in range(num_test_reviews):\n",
    "    cleaned_test_reviews.append(preprocess_review( test[\"review\"][i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIq31H_fR1Tm"
   },
   "source": [
    "## 1. Processing Text to create Design Matrices [15 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urCR0VMaR1Tn"
   },
   "outputs": [],
   "source": [
    "def design_matrix(cleaned_reviews):\n",
    "    \"\"\" Generate the 4 design matrices X_counts, X_binary, X_tfidf, X_binary_imbalance.\n",
    "\n",
    "      Args: cleaned_reviews: Cleaned Reviews.\n",
    "      Returns:\n",
    "            X_counts: Design Matrix X_counts.\n",
    "            X_binary: Design Matrix X_binary(Use the X_counts to generate this.)\n",
    "            X_tfidf:  Design Matrix X_tfidf\n",
    "            X_binary_imbalance: Design Matrix X_binary_imbalance(use fraction 0.75)\n",
    "            imbalance_train: Skewed training set(use fraction 0.75)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #Write your code below \n",
    "    #Create X_counts\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, \\\n",
    "                                 stop_words = None, max_features = 5000) \n",
    "    X_counts = vectorizer.fit_transform(cleaned_reviews)\n",
    "    X_counts = X_counts.toarray()\n",
    "    \n",
    "    #create X_binary\n",
    "    X_binary= np.copy(X_counts)\n",
    "    X_binary[X_binary > 0] = 1\n",
    "    #print(X_binary[0].sum())\n",
    "    #print(X_counts[0].sum())\n",
    "    \n",
    "    #create X_tfidf\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    X_tfidf= transformer.fit_transform(X_counts)\n",
    "    X_tfidf= X_tfidf.toarray()\n",
    "    #print(X_tfidf[0].sum())\n",
    "    \n",
    "    #create list of indexes to be deleted for the imbalanced design matricies\n",
    "    np.random.seed(0)\n",
    "    idxs= np.array(train.index[train['sentiment'] == 1].tolist())\n",
    "    np.random.shuffle(idxs)\n",
    "    split=int(len(idxs)*.75)\n",
    "    del_idxs=idxs[0:split]\n",
    "    #tee=del_idxs\n",
    "    #print(np.sort(tee))\n",
    "    \n",
    "    #create X_binary_imbalance\n",
    "    X_binary_imbalance= np.delete(X_binary,del_idxs, axis=0)\n",
    "    #print(X_binary_imbalance[0].sum())\n",
    "    \n",
    "    #create imbalance_train\n",
    "    imbalance_train=train.copy()\n",
    "    imbalance_train.drop(imbalance_train.index[list(del_idxs)],inplace=True)\n",
    "    imbalance_train.reset_index(inplace=True, drop=True)\n",
    "    #print(imbalance_train)\n",
    "    \n",
    "    return X_counts,X_binary,X_tfidf,X_binary_imbalance,imbalance_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_counts,X_binary,X_tfidf,X_binary_imbalance,imbalance_train= design_matrix(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POPvMtKER1Tp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kt4EPPLR1Tx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xBH1DKHuR1T1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcHBxl31R1T7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_binary_imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5s2xUvMR1T-"
   },
   "source": [
    "## 2. Feature Space Similarity Experiment [25(5 + 5 + 15) Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRPAXIfDR1T_"
   },
   "outputs": [],
   "source": [
    "# Obtain the label on the original train set and imbalance train set\n",
    "train_sentiment = train[\"sentiment\"].values\n",
    "imbalance_train_sentiment = imbalance_train[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgK6cWOKUhIJ"
   },
   "outputs": [],
   "source": [
    "def dist(X, i, j, distance_function = \"euclidean\"):\n",
    "    \"\"\"The distance function returns the (Euclidean) distance between rows i and j of a design matrix.\n",
    "     Args: X : Design Matrix\n",
    "           i,j: row IDs\n",
    "           distance_function: The distance function to be used. Here we are using euclidean\n",
    "     Returns: The distance between row i and row j.\n",
    "  \n",
    "    \"\"\"\n",
    "    #Write your code here.\n",
    "    r1=X[i]\n",
    "    r2=X[j]\n",
    "    d=r2-r1\n",
    "    d=d*d\n",
    "    distance=d.sum()\n",
    "    distance=np.sqrt(distance)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWvROZUqUnvJ"
   },
   "outputs": [],
   "source": [
    "def topk(X, k):\n",
    "    \"\"\"The topk(X, k) function returns ((i1,j1,d1),...(ik,jk,dk)) where (ix,jx) are the indices of the xth \n",
    "     closest pair, and dx is the corresponding distance. You can break ties randomly.\n",
    "     Args: X : Design Matrix\n",
    "           k:  Top k\n",
    "     Returns: top: A list of [row,col,distance]\n",
    "  \n",
    "    \"\"\"\n",
    "   \n",
    "    #Write your code here.\n",
    "    dm=pairwise_distances(X)\n",
    "    shape= dm.shape\n",
    "    tri_idx=np.triu_indices(dm.shape[0],1)\n",
    "    dm=dm[tri_idx]\n",
    "    idx= np.argpartition(dm, k)[:k]\n",
    "    vals=dm[idx]\n",
    "    idx=np.array(tri_idx).T[idx]\n",
    "    top= np.vstack([idx[:,0],idx[:,1],vals]).T\n",
    "    \n",
    "    return top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6QQdWA7BmMZ"
   },
   "source": [
    "Use topk() to find the closest review pairs for each design matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-pJSPn0a3NA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_i:  4543.0\n",
      "index_j:  12168.0\n",
      "distance:  0.0\n",
      "i_characters:  Smallville episode J\n",
      "j_characters:  Smallville episode J\n",
      "i_sent:  1\n",
      "j_sent:  1\n",
      "\n",
      "index_i:  6035.0\n",
      "index_j:  18501.0\n",
      "distance:  0.0\n",
      "i_characters:  Corridors of time. T\n",
      "j_characters:  Corridors of time. T\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  7765.0\n",
      "index_j:  9776.0\n",
      "distance:  0.0\n",
      "i_characters:  How has this piece o\n",
      "j_characters:  How has this piece o\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  612.0\n",
      "index_j:  10730.0\n",
      "distance:  0.0\n",
      "i_characters:  There is no reason t\n",
      "j_characters:  There is no reason t\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  2893.0\n",
      "index_j:  12983.0\n",
      "distance:  0.0\n",
      "i_characters:  If you want Scream o\n",
      "j_characters:  If you want Scream o\n",
      "i_sent:  1\n",
      "j_sent:  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute top k for X_counts matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
    "#Write your code here.\n",
    "\n",
    "\n",
    "close_k= topk(X_counts,5)\n",
    "for ck in close_k:\n",
    "    i,j,d= ck\n",
    "    ichars= train[\"review\"][i][0:20]\n",
    "    jchars= train[\"review\"][j][0:20]\n",
    "    isent= train[\"sentiment\"][i]\n",
    "    jsent= train[\"sentiment\"][j]\n",
    "    print(\"index_i: \",i)\n",
    "    print(\"index_j: \",j)\n",
    "    print(\"distance: \",d)\n",
    "    print(\"i_characters: \",ichars)\n",
    "    print(\"j_characters: \",jchars)\n",
    "    print(\"i_sent: \",isent)\n",
    "    print(\"j_sent: \",jsent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkvjeJMTaFTS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_i:  4723.0\n",
      "index_j:  9740.0\n",
      "distance:  0.0\n",
      "i_characters:  This movie got off t\n",
      "j_characters:  This movie got off t\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  3256.0\n",
      "index_j:  23321.0\n",
      "distance:  0.0\n",
      "i_characters:  You do realize that \n",
      "j_characters:  You do realize that \n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  5519.0\n",
      "index_j:  14734.0\n",
      "distance:  0.0\n",
      "i_characters:  'Dead Letter Office'\n",
      "j_characters:  'Dead Letter Office'\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  2018.0\n",
      "index_j:  6396.0\n",
      "distance:  0.0\n",
      "i_characters:  I find it rather use\n",
      "j_characters:  I find it rather use\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  14104.0\n",
      "index_j:  22961.0\n",
      "distance:  0.0\n",
      "i_characters:  I like a lot of the \n",
      "j_characters:  I like a lot of the \n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute top k for X_binary matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
    "#Write your code here.\n",
    "\n",
    "close_k= topk(X_binary,5)\n",
    "for ck in close_k:\n",
    "    i,j,d= ck\n",
    "    ichars= train[\"review\"][i][0:20]\n",
    "    jchars= train[\"review\"][j][0:20]\n",
    "    isent= train[\"sentiment\"][i]\n",
    "    jsent= train[\"sentiment\"][j]\n",
    "    print(\"index_i: \",i)\n",
    "    print(\"index_j: \",j)\n",
    "    print(\"distance: \",d)\n",
    "    print(\"i_characters: \",ichars)\n",
    "    print(\"j_characters: \",jchars)\n",
    "    print(\"i_sent: \",isent)\n",
    "    print(\"j_sent: \",jsent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OITNkuZUaOu_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_i:  1461.0\n",
      "index_j:  6013.0\n",
      "distance:  0.0\n",
      "i_characters:  I really enjoyed thi\n",
      "j_characters:  I really enjoyed thi\n",
      "i_sent:  1\n",
      "j_sent:  1\n",
      "\n",
      "index_i:  15426.0\n",
      "index_j:  21441.0\n",
      "distance:  0.0\n",
      "i_characters:  As a low budget ente\n",
      "j_characters:  As a low budget ente\n",
      "i_sent:  1\n",
      "j_sent:  1\n",
      "\n",
      "index_i:  2465.0\n",
      "index_j:  16917.0\n",
      "distance:  0.0\n",
      "i_characters:  God, I was bored out\n",
      "j_characters:  God, I was bored out\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  15290.0\n",
      "index_j:  18042.0\n",
      "distance:  0.0\n",
      "i_characters:  This show comes up w\n",
      "j_characters:  This show comes up w\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  8255.0\n",
      "index_j:  19847.0\n",
      "distance:  0.0\n",
      "i_characters:  After losing the Emm\n",
      "j_characters:  After losing the Emm\n",
      "i_sent:  1\n",
      "j_sent:  1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute top k for X_tfidf matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
    "#Write your code here.\n",
    "\n",
    "close_k= topk(X_tfidf,5)\n",
    "for ck in close_k:\n",
    "    i,j,d= ck\n",
    "    ichars= train[\"review\"][i][0:20]\n",
    "    jchars= train[\"review\"][j][0:20]\n",
    "    isent= train[\"sentiment\"][i]\n",
    "    jsent= train[\"sentiment\"][j]\n",
    "    print(\"index_i: \",i)\n",
    "    print(\"index_j: \",j)\n",
    "    print(\"distance: \",d)\n",
    "    print(\"i_characters: \",ichars)\n",
    "    print(\"j_characters: \",jchars)\n",
    "    print(\"i_sent: \",isent)\n",
    "    print(\"j_sent: \",jsent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckNqY0ZbaU-z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_i:  3109.0\n",
      "index_j:  4747.0\n",
      "distance:  0.0\n",
      "i_characters:  When i got this movi\n",
      "j_characters:  When i got this movi\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  7741.0\n",
      "index_j:  15495.0\n",
      "distance:  0.0\n",
      "i_characters:  This film was so ama\n",
      "j_characters:  This film was so ama\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  2054.0\n",
      "index_j:  5849.0\n",
      "distance:  0.0\n",
      "i_characters:  In 1993, \\the visito\n",
      "j_characters:  In 1993, \\the visito\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  9658.0\n",
      "index_j:  14492.0\n",
      "distance:  0.0\n",
      "i_characters:  What was an exciting\n",
      "j_characters:  What was an exciting\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n",
      "index_i:  7745.0\n",
      "index_j:  10662.0\n",
      "distance:  0.0\n",
      "i_characters:  The story and the sh\n",
      "j_characters:  The story and the sh\n",
      "i_sent:  0\n",
      "j_sent:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute top k for X_binary_imbalance matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
    "#Write your code here.\n",
    "\n",
    "close_k= topk(X_binary_imbalance,5)\n",
    "for ck in close_k:\n",
    "    i,j,d= ck\n",
    "    ichars= imbalance_train[\"review\"][i][0:20]\n",
    "    jchars= imbalance_train[\"review\"][j][0:20]\n",
    "    isent= imbalance_train[\"sentiment\"][i]\n",
    "    jsent= imbalance_train[\"sentiment\"][j]\n",
    "    print(\"index_i: \",i)\n",
    "    print(\"index_j: \",j)\n",
    "    print(\"distance: \",d)\n",
    "    print(\"i_characters: \",ichars)\n",
    "    print(\"j_characters: \",jchars)\n",
    "    print(\"i_sent: \",isent)\n",
    "    print(\"j_sent: \",jsent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESA7ElrMbHEw"
   },
   "source": [
    "Are the pairs always the same?\n",
    "\n",
    "A: No they are not always the same. They are only the same for X_counts and X_binary. They are different for X_tfidf and X_binary_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yywNrWhlbQ10"
   },
   "source": [
    "## 3. Classification Experiment [35 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mo8UaxPjCr9Q"
   },
   "source": [
    "Now you’re going to tune an SVM classifier using each design matrix, and measure the\n",
    "resultant performance. Read the sklearn [docs](http://scikit-learn.org/stable/modules/cross_validation.html) on cross-validation to see the\n",
    "methods to use.\n",
    "*   Set your rng seed to 0 and create an initial learning_set / test_set split of 80-20.\n",
    "*   Now we want to use a linear SVM (svm.SVC with kernel=linear) and pick the best C value for our classifier.\n",
    "*   Repeat for each of the four design matrices:\n",
    "  *  Repeat 30 times:\n",
    "    *  Pick a random value of C uniformly in the interval (1e-4, 1e4).\n",
    "    *  Use 5-fold cross-validation to train the SVM.\n",
    "    *  Estimate and record the F1-Score.\n",
    "  *  Select the value of C which produced the best F1-Score and find out the F1-Score on the test set using that C.\n",
    "  *  Retrain the classifier using the entire learning set with this C value.\n",
    "  *  Submit test set predictions to Kaggle (see the section in the blog, and\n",
    "make sure you use their test data. You may need to retrain one more\n",
    "time using all “training data”). Print your Kaggle score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9La4ICibWl6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD98GcZ9jJ2b"
   },
   "source": [
    "### 3.1 Utility Functions [10 (5 + 5) Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9K2mD7pe9Bc"
   },
   "outputs": [],
   "source": [
    "def calculateF1(X, y, k = 5):\n",
    "    \"\"\"calculateF1(X, y, k = 5) return two list which record all randomly selected c(in the interval (1e-4, 1e4))\n",
    "     and corresponding F1 scores.\n",
    "\n",
    "     Args: X: Features\n",
    "           y: Label of sentiment\n",
    "           k: Number of Cross-validation\n",
    "\n",
    "     Returns: c_list: List of all c values.\n",
    "              f1_list: Corresponding F1 Scores.\n",
    "    \"\"\"\n",
    "    rd.seed(0) #Setting a common seed\n",
    "\n",
    "    #Write your code here.\n",
    "    cv= KFold(n_splits= k)\n",
    "    c_list= []\n",
    "    f1_list= []\n",
    "    \n",
    "    for i in range(30):\n",
    "        c= rd.uniform(-4, 4)\n",
    "        c= 10**c\n",
    "        f1=0\n",
    "        clf= svm.LinearSVC(C= c)\n",
    "        \n",
    "        for train, test in cv.split(X, y):\n",
    "            clf.fit(X[train], y[train])\n",
    "            y_pred = clf.predict(X[test])\n",
    "            temp_f1 = f1_score(y[test], y_pred)\n",
    "            f1 = f1+temp_f1\n",
    "            \n",
    "        f1=f1/k\n",
    "        c_list.append(c)\n",
    "        f1_list.append(f1)\n",
    "        \n",
    "    return c_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ah82TDqCgKaN"
   },
   "outputs": [],
   "source": [
    "def findBestC(X, y, k = 5):\n",
    "    \"\"\"findBestC(X, y, k) return the best performance c, and the improvement(difference between best and worst f1_scores)/\n",
    "     Args: X: Features\n",
    "           y: Label of sentiment\n",
    "           k: Number of Cross-validation\n",
    "     Returns: c_best: C value with best f1_score.\n",
    "              improvement: difference between best and worst f1_score.\n",
    "    \"\"\"\n",
    "    c_list, f1_list= calculateF1(X, y,k)\n",
    "    best_idx= np.argmax(f1_list)\n",
    "    worst_idx= np.argmin(f1_list)\n",
    "    c_best=c_list[best_idx]\n",
    "    improvement= f1_list[best_idx]-f1_list[worst_idx]     \n",
    "    \n",
    "    return c_best,improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aAMZU6YBjUVU"
   },
   "source": [
    "### 3.2 Tune an SVM classifier using X_counts [20 (4*5) Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVatM_PprZpC"
   },
   "source": [
    "#### 3.2.0 Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFjJKZKelYl5"
   },
   "outputs": [],
   "source": [
    "def findImprovement(X,train_sentiment,test_size = 0.2, random_state = 0):\n",
    "    \"\"\" Find the improvement in F1-Score of the design Matrix(X) using previous utility functions and the test_f1_score using the best C.\n",
    "\n",
    "      Args: X: Design Matrix\n",
    "            train_sentiment: Sentiments of the training data\n",
    "            test_size: Split it as 80:20\n",
    "            random_state: Seed\n",
    "\n",
    "      Returns:\n",
    "            c_best: The best possible c value\n",
    "            improvement: improvement in F1-Score using the design Matrix(X).\n",
    "            f1_s: Test F1 Score.\n",
    "            \n",
    "\n",
    "      You should carry out the following Steps:\n",
    "      1. Split the data using the above parameters.\n",
    "      2. Find out the best c and the improvement. (use 5-fold Cross Validation.)\n",
    "      3. Find out the test f1 score with this c.\n",
    "    \"\"\"\n",
    "    #Write your code here.\n",
    "    X_train, X_test, y_train, y_test= train_test_split(X,train_sentiment, test_size = 0.2, random_state = 0)\n",
    "    c_best, improvement= findBestC(X_train, y_train, 5)\n",
    "    clf= svm.LinearSVC(C = c_best)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    f1_s= f1_score(y_test, y_pred)\n",
    "\n",
    "    return c_best,improvement,f1_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f90fpHRiq1IM"
   },
   "source": [
    "#### 3.2.1 Tune an SVM classifier using X_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtON_6r5jgTL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_best:  0.010093707860257255\n",
      "improvement:  0.053691953325930575\n",
      "f1_s:  0.8756299133239266\n"
     ]
    }
   ],
   "source": [
    "#Print the improvement using X_counts and the test f1_score using the best c.\n",
    "#Write your code here.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "c_best,improvement,f1_s= findImprovement(X_counts,train_sentiment,test_size = 0.2, random_state = 0)\n",
    "print(\"c_best: \",c_best)\n",
    "print(\"improvement: \",improvement)\n",
    "print(\"f1_s: \",f1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IygnGs8blBu-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.010093707860257255, class_weight=None, dual=True,\n",
       "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the classifier using the entire learning set with c_best\n",
    "#Write your code here.\n",
    "xc_clf= svm.LinearSVC(C = c_best)\n",
    "xc_clf.fit(X_counts, train_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IunoAYI6pgZW"
   },
   "source": [
    "Submit test set predictions to Kaggle (see the section in the blog, and\n",
    "make sure you use their test data. You may need to retrain one more\n",
    "time using all “training data”). Print your Kaggle scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9aRF1HA7lHAP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kaggle Score using X_counts is 0.54072\n"
     ]
    }
   ],
   "source": [
    "#You should do the following steps.\n",
    "#1. Create bag of words from the test data.\n",
    "#2. Generate the labels using that test data.\n",
    "#3. Save the results to the pandas dataframe. For format check the blog.\n",
    "#4. Submit the results to Kaggle and add the scores here.\n",
    "\n",
    "#Write your code here.\n",
    "X_counts_test, X_binary_test, X_tfidf_test, X_binary_imbalance_test, imbalance_test= design_matrix(cleaned_test_reviews)\n",
    "xc_pred= xc_clf.predict(X_counts_test)\n",
    "xc_output= pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":xc_pred})\n",
    "xc_output.to_csv(\"xcounts.csv\", index=False)\n",
    "\n",
    "#Uncomment the below lines and add your score.\n",
    "X_counts_result = 0.54072\n",
    "print(\"The Kaggle Score using X_counts is {}\".format(X_counts_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYRrpQtvrAKF"
   },
   "source": [
    "#### 3.2.2 Tune an SVM classifier using X_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVwbgdUJrD5h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_best:  0.010093707860257255\n",
      "improvement:  0.055924091917174956\n",
      "f1_s:  0.8713509160459029\n"
     ]
    }
   ],
   "source": [
    "#Print the improvement using X_binary and the test f1_score using the best c.\n",
    "#Write your code here.\n",
    "c_best,improvement,f1_s= findImprovement(X_binary,train_sentiment,test_size = 0.2, random_state = 0)\n",
    "print(\"c_best: \",c_best)\n",
    "print(\"improvement: \",improvement)\n",
    "print(\"f1_s: \",f1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hI0KVsQjsGHa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.010093707860257255, class_weight=None, dual=True,\n",
       "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the classifier using the entire learning set with c_best\n",
    "#Write your code here.\n",
    "xb_clf= svm.LinearSVC(C = c_best)\n",
    "xb_clf.fit(X_binary, train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zpgOR4NsdrP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kaggle Score using X_binary is 0.55152\n"
     ]
    }
   ],
   "source": [
    "#Use the the same steps as you did for X_counts and print the kaggle score. Please note that you need to find X_binary_test using the X_counts_test.\n",
    "#Write your code here.\n",
    "xb_pred= xb_clf.predict(X_binary_test)\n",
    "xb_output= pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":xb_pred})\n",
    "xb_output.to_csv(\"xbinary.csv\", index=False)\n",
    "\n",
    "\n",
    "#Uncomment the below lines and add your score.\n",
    "X_binary_result = 0.55152\n",
    "print(\"The Kaggle Score using X_binary is {}\".format(X_binary_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRHMJO2os_tc"
   },
   "source": [
    "#### 3.2.3 Tune an SVM classifier using X_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnm8PdFWtGE9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_best:  0.173569374988568\n",
      "improvement:  0.06279354208338983\n",
      "f1_s:  0.888083735909823\n"
     ]
    }
   ],
   "source": [
    "#Print the improvement using X_tf_idf and the test f1_score using the best c.\n",
    "#Write your code here.\n",
    "c_best,improvement,f1_s= findImprovement(X_tfidf,train_sentiment,test_size = 0.2, random_state = 0)\n",
    "print(\"c_best: \",c_best)\n",
    "print(\"improvement: \",improvement)\n",
    "print(\"f1_s: \",f1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWXXKrgGtU-r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.173569374988568, class_weight=None, dual=True,\n",
       "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain svm using all X_tfidf data\n",
    "#Write your code here.\n",
    "xt_clf= svm.LinearSVC(C = c_best)\n",
    "xt_clf.fit(X_tfidf, train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waBnpKAztX_H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kaggle Score using X_tfidf is 0.56943\n"
     ]
    }
   ],
   "source": [
    "#Use the the same steps as you did for X_counts and print the kaggle score. Please note that you need to find X_tfidf_test using the X_counts_test.\n",
    "\n",
    "#Write your code here.\n",
    "xt_pred= xt_clf.predict(X_tfidf_test)\n",
    "xt_output= pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":xt_pred})\n",
    "xt_output.to_csv(\"xtfidf.csv\", index=False)\n",
    "\n",
    "\n",
    "#Uncomment the below lines and add your score.\n",
    "X_tfidf_result = 0.56943\n",
    "print(\"The Kaggle Score using X_tfidf is {}\".format(X_tfidf_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GSTHOCktwVf"
   },
   "source": [
    "#### 3.2.4 Tune an SVM classifier using X_binary_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWPad9EXtzKD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_best:  0.01797640132539557\n",
      "improvement:  0.21287935039895012\n",
      "f1_s:  0.7214225232853515\n"
     ]
    }
   ],
   "source": [
    "#Print the improvement using X_binary_imbalance and the test f1_score using the best c.\n",
    "#Write your code here.\n",
    "c_best,improvement,f1_s= findImprovement(X_binary_imbalance,imbalance_train_sentiment,test_size = 0.2, random_state = 0)\n",
    "print(\"c_best: \",c_best)\n",
    "print(\"improvement: \",improvement)\n",
    "print(\"f1_s: \",f1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUsNuBpouEL-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01797640132539557, class_weight=None, dual=True,\n",
       "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain svm using all X_binary_imbalance data.\n",
    "#Write your code here.\n",
    "xbi_clf= svm.LinearSVC(C = c_best)\n",
    "xbi_clf.fit(X_binary_imbalance, imbalance_train_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6YJvYHkuFh8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kaggle Score using X_binary_imbalance is 0.51752\n"
     ]
    }
   ],
   "source": [
    "#Use the the same steps as you did for X_counts and print the kaggle score.\n",
    "\n",
    "#Write your code here.\n",
    "xbi_pred= xbi_clf.predict(X_binary_test)\n",
    "xbi_output= pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":xbi_pred})\n",
    "xbi_output.to_csv(\"xbi.csv\", index=False)\n",
    "\n",
    "\n",
    "#Uncomment the below lines and add your score.\n",
    "X_binary_imbalance_result = 0.51752\n",
    "print(\"The Kaggle Score using X_binary_imbalance is {}\".format(X_binary_imbalance_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRxZro0LMixK"
   },
   "source": [
    "Which design matrix performed best (e.g., which encoding method worked best)?\n",
    "\n",
    "A: X_tfidf performed the best, as it had the best test accuracy. \n",
    "\n",
    "What was the lift (improvement in F1-Score) between the worst and best cases for each experiment?\n",
    "\n",
    "A: <br>\n",
    "1) X_count: 0.0536129817027462<br>\n",
    "2) X_binary: 0.055924091917174956<br>\n",
    "3) X_tfidf: 0.062375758495022526<br>\n",
    "4) X_counts: 0.21287935039895012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFjZq14Subsb"
   },
   "source": [
    "##4. Learning Curve Experiment [15(10 + 5) Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LfArmX7M0-9"
   },
   "source": [
    "Using a logistic regression classifier and the design matrix X_counts, generate a learning curve:\n",
    "*  Set your rng seed to 0 and create an initial learning_set / test_set split of 80-20.\n",
    "*  Generate a learning curve (xval vs training error) for n=(100, 500, 1000, 2000,3000, 4000, 5000, 7500, 10000, 15000, 20000) training instances.\n",
    "*  Interpret the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZy1W2wCNRrU"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQYNGVZYugpY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_instances = [100, 500, 1000, 2000, 3000, 4000, 5000, 7500, 10000, 15000, 20000]\n",
    "#Use the learning_curve module to generate mean train and test scores and plot them with X-axis being the number of training instances and Y-axis.\n",
    "#Please add appropriate title,labels and legends.\n",
    "\n",
    "#Write your code here.\n",
    "val, trs, tes= learning_curve(LogisticRegression(), X_counts, train_sentiment, cv = 5, train_sizes = training_instances)\n",
    "tr_error= 1-np.mean(trs, axis= 1)\n",
    "te_error= 1-np.mean(tes, axis= 1)\n",
    "\n",
    "plt.plot(training_instances, tr_error, 'o-', label = \"Train Error\", color = \"b\")\n",
    "plt.plot(training_instances, te_error, 'o-', label = \"Test Error\", color = \"r\")\n",
    "plt.title(\"Logistic Regression Learning Curves\")\n",
    "plt.xlabel(\"Training Instances\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xm0dRZbpScvV"
   },
   "source": [
    "##### Please provide an explanation to the nature of your graph in the above experiment.\n",
    "\n",
    "The training error starts off near 0, then increases as the training size increases, whereas the the test error starts off high and decreases as the training size increases. This is becasue when there are few data points, the regression model can be skewed by outliers or even data points being differently distributed than the whole set of data points. This leads to high test errors as the model can be overfit to the training set and fails to generalize. However, as the number of data points increases, they tend to be more indicicative of the whole set, and so the testing error comes down, and since more points are incorporated into training, the training error rises as a linear svm has a tougher time coming up with the seperation boudary to fit all points. Therefore the training and testing errors seem to be converging."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_CSE_6240_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
